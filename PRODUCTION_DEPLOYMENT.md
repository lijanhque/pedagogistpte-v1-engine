# PTE Academic Scoring Engine – Complete Production Deployment

This is a comprehensive, production-ready **PTE Academic test scoring engine** implementing Levels 1–5 of the architecture:

- **Level 1:** RESTful API with CRUD operations for assessments and synchronous scoring
- **Level 2:** Background job processing with Redis queues (RQ) and async workers
- **Level 3:** Centralized workflow orchestration with Redis pub/sub and state management
- **Level 4:** AI agent integration with Vercel AI Gateway, Google GenAI, and local NLP models
- **Level 5:** Real-time streaming updates via Server-Sent Events (SSE) and Redis pub/sub

## Architecture Overview

```
┌──────────────────────────────────────────────────────────────────────┐
│                         Next.js Frontend (Vercel)                    │
│                    + Vercel AI SDK v5 / Gateway Client               │
└────────────┬─────────────────────────────────────────────────────────┘
             │ HTTP/SSE
             │
┌────────────▼─────────────────────────────────────────────────────────┐
│              FastAPI Scoring Service (Level 1-5)                      │
│  ┌────────────────────────────────────────────────────────────────┐  │
│  │ Level 1: CRUD Endpoints                                        │  │
│  │  - POST /assessments (create)                                 │  │
│  │  - GET /assessments/{id} (retrieve)                           │  │
│  │  - POST /score (sync scoring)                                 │  │
│  └────────────────────────────────────────────────────────────────┘  │
│  ┌────────────────────────────────────────────────────────────────┐  │
│  │ Level 2: Background Jobs + RQ Worker                          │  │
│  │  - POST /jobs (enqueue background job)                        │  │
│  │  - GET /jobs/{id} (track job status)                          │  │
│  │  - Worker processes scoring in background                     │  │
│  └────────────────────────────────────────────────────────────────┘  │
│  ┌────────────────────────────────────────────────────────────────┐  │
│  │ Level 3: Orchestration + State Management (Redis)             │  │
│  │  - Job state transitions: pending → processing → scored →...  │  │
│  │  - Redis pubsub for event broadcasting                        │  │
│  │  - Audit logging of all scoring actions                       │  │
│  └────────────────────────────────────────────────────────────────┘  │
│  ┌────────────────────────────────────────────────────────────────┐  │
│  │ Level 4: AI Agents (Vercel + Google + Local)                  │  │
│  │  - ScoringAgent with fallback: Vercel → Google → Local NLP    │  │
│  │  - Hybrid scoring: AI + local rule-based results              │  │
│  │  - Prompt templates for consistent model inputs               │  │
│  └────────────────────────────────────────────────────────────────┘  │
│  ┌────────────────────────────────────────────────────────────────┐  │
│  │ Level 5: Streaming Updates (SSE + Redis pub/sub)              │  │
│  │  - GET /stream/scoring/{job_id} (real-time job updates)       │  │
│  │  - GET /stream/scores/{job_id} (final scores stream)          │  │
│  │  - Scalable across multiple instances with pub/sub            │  │
│  └────────────────────────────────────────────────────────────────┘  │
└────────────────────────────────────────────────────────────────────────┘
             │
     ┌───────┴────────┬──────────┐
     │                │          │
  Redis           Postgres   (Optional)
 Queues, Pub/Sub  Persistent State
```

## Accurate PTE Scoring

The `PTEScorer` class implements multi-dimensional academic English assessment:

### Scoring Dimensions

1. **Fluency & Coherence** (25% weight)
   - Lexical diversity (Type-Token Ratio)
   - Sentence complexity and variation
   - Discourse markers and connectives

2. **Lexical Resource** (25% weight)
   - Vocabulary range (CEFR classification: A1–C2)
   - Academic word usage
   - Synonym variety to avoid repetition

3. **Grammar** (20% weight)
   - Subject-verb agreement
   - Tense consistency and accuracy
   - Sentence construction complexity

4. **Oral Fluency** (15% weight)
   - Filler word detection (um, uh, like, etc.)
   - Pacing estimation
   - Hesitation markers

5. **Pronunciation (Proxy)** (15% weight)
   - Phonetic complexity from text analysis
   - Difficult sound combinations
   - Syllable patterns

### Calibration

- **Composite score:** Weighted combination of all dimensions (0–100)
- **PTE Band:** Calibrated to PTE's 10–90 band scale
- **Section Score:** Mapped to 0–90 for reporting

### AI Enhancement

When AI agents are enabled (Vercel AI Gateway or Google GenAI), scores are:
- Generated by the LLM for each dimension independently
- Combined (50/50 weight) with local rule-based scores
- Provides nuanced, context-aware scoring

## Quick Start

### Prerequisites

- Docker & Docker Compose
- Python 3.12+ (for local dev without containers)
- Node.js 18+ (for Next.js frontend)
- Vercel AI Gateway key (optional, for premium scoring)
- Google GenAI key (optional, for fallback model)

### Local Development (Docker Compose)

1. **Clone and setup:**
   ```bash
   git clone <repo>
   cd pedagogistpte-v1-engine
   cp services/scoring_api/.env.example .env
   ```

2. **Populate environment variables in `.env`:**
   ```bash
   SCORE_MODE=sync                    # or "async" for background jobs
   VERCEL_AI_GATEWAY_KEY=your_key     # Optional
   GOOGLE_GENAI_KEY=your_key          # Optional
   REDIS_URL=redis://redis:6379/0
   ```

3. **Start all services:**
   ```bash
   docker compose up --build
   ```

   This starts:
   - **API:** http://localhost:8000 (OpenAPI docs: `/docs`)
   - **Redis:** localhost:6379
   - **Worker:** Processes jobs from the queue

4. **Test the API:**
   ```bash
   curl -X POST http://localhost:8000/score \
     -H "Content-Type: application/json" \
     -d '{
       "text": "The technological revolution has dramatically transformed society in unprecedented ways.",
       "metadata": {"submission_type": "speaking"}
     }'
   ```

### Example Requests

#### Synchronous Scoring (Level 1)

```bash
curl -X POST http://localhost:8000/score \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Climate change represents one of the most significant challenges facing humanity today. The rapid increase in global temperatures, driven primarily by anthropogenic greenhouse gas emissions, has precipitated cascading ecological disruptions and socioeconomic consequences.",
    "metadata": {"submission_type": "academic_writing"}
  }'
```

**Response:**
```json
{
  "scores": {
    "fluency": 78,
    "lexical_resource": 82,
    "grammar": 75,
    "oral_fluency": 70,
    "pronunciation": 72
  },
  "model": {
    "name": "pte_academic_v1",
    "ai_used": false
  },
  "raw": {
    "composite": 75.4,
    "band": 70,
    "section_score": 65,
    "breakdown": {
      "word_count": 50,
      "sentence_count": 3,
      "avg_sentence_length": 16.7,
      "lexical_diversity": 0.84,
      "filler_count": 0
    }
  }
}
```

#### Background Job (Level 2/3)

```bash
# Create job
curl -X POST http://localhost:8000/jobs \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Sample submission...",
    "metadata": {"student_id": "STU001"}
  }'

# Response:
# {"job_id": "abc123", "state": "pending", ...}

# Get status
curl http://localhost:8000/jobs/abc123

# Enqueue to worker
curl -X POST http://localhost:8000/jobs/abc123/enqueue
```

#### Real-Time Streaming (Level 5)

```bash
# Subscribe to job updates via SSE
curl -N http://localhost:8000/stream/scoring/abc123

# You'll receive events like:
# data: {"type":"job_state_changed","data":{"state":"processing",...}}
# data: {"type":"job_enriched","data":{"enrichment":{...}}}
# data: {"type":"scores_ready","job":{...}}
```

#### AI-Powered Scoring (Level 4)

```bash
curl -X POST http://localhost:8000/score/with-ai \
  -H "Content-Type: application/json" \
  -d '{
    "text": "The future of education hinges on integrating artificial intelligence...",
    "metadata": {}
  }'

# Combines AI (Vercel Gateway) + local NLP for hybrid scores
```

## Environment Variables

| Variable | Required | Description |
|----------|----------|-------------|
| `SCORE_MODE` | No | `"sync"` (default) or `"async"` for background processing |
| `REDIS_URL` | No | Redis connection URL (default: `redis://localhost:6379/0`) |
| `VERCEL_AI_GATEWAY_KEY` | No | API key for Vercel AI Gateway |
| `GOOGLE_GENAI_KEY` | No | API key for Google GenAI (fallback) |
| `APP_ENV` | No | `"development"` or `"production"` |

## Production Deployment

### Python Services (Docker)

Deploy as containerized services on any cloud provider:

1. **Build image:**
   ```bash
   docker build -t pte-scoring-api:latest ./services/scoring_api
   ```

2. **Push to registry (e.g., ECR, Docker Hub):**
   ```bash
   docker tag pte-scoring-api:latest <registry>/pte-scoring-api:latest
   docker push <registry>/pte-scoring-api:latest
   ```

3. **Deploy to ECS, Kubernetes, or Docker Swarm:**
   - **Replicas:** 2–3 for high availability
   - **Port:** 8000
   - **Environment:** Set all secret env vars via your orchestrator
   - **Health check:** GET /health (returns 200)

4. **Deploy worker separately:**
   ```bash
   # Override entrypoint to run worker
   docker run -e REDIS_URL=redis://redis-cluster:6379/0 \
     pte-scoring-api:latest rq worker scoring
   ```

### Next.js Frontend (Vercel)

1. **Install Vercel CLI:**
   ```bash
   npm i -g vercel
   ```

2. **Deploy:**
   ```bash
   cd app  # or your Next.js directory
   vercel deploy --prod
   ```

3. **Set environment variables in Vercel dashboard:**
   - `NEXT_PUBLIC_SCORING_API_URL`: https://api-prod.example.com
   - `VERCEL_AI_GATEWAY_KEY`: Your API key (for client-side model calls)

### Infrastructure Setup

**Recommended stack for production:**

| Component | Solution |
|-----------|----------|
| API Host | AWS ECS / Kubernetes / DigitalOcean App Platform |
| Redis | AWS ElastiCache / Redis Cloud / UpStash |
| Postgres | AWS RDS / DigitalOcean Managed DB / Supabase |
| Frontend | Vercel |
| Domain/SSL | Cloudflare / AWS Route53 |
| Monitoring | Sentry / DataDog / New Relic |

## Testing

Run the full test suite locally:

```bash
cd services/scoring_api
pip install -r requirements.txt
pytest tests/ -v --cov=app
```

Or with Docker:

```bash
docker compose exec scoring_api pytest tests/ -v
```

**Test coverage includes:**
- Unit tests for PTE scorer (fluency, lexical resource, grammar, etc.)
- Integration tests for API endpoints
- Mock tests for Vercel Gateway and Google GenAI
- Orchestrator state machine tests
- Streaming endpoint tests

## CI/CD

GitHub Actions workflow runs on every push to `main`:

```bash
cat .github/workflows/scoring-api-ci.yml
```

- Runs tests with Redis service
- Builds Docker image
- Optional linting and security scans

## API Documentation

Interactive API docs available at `/docs` (Swagger UI):

```
http://localhost:8000/docs
```

Or ReDoc format at `/redoc`.

## Performance & Scalability

- **Async processing:** RQ workers auto-scale with job queue size
- **Streaming:** Server-Sent Events avoid long polling overhead
- **Caching:** Redis cache for model outputs and repeated submissions
- **Pagination:** Job listing supports pagination for large datasets (future)
- **Batch scoring:** Endpoint to score multiple submissions in one request (future)

## Security Best Practices

1. **Secrets management:**
   - Store `VERCEL_AI_GATEWAY_KEY`, `GOOGLE_GENAI_KEY` in your platform's secret manager (AWS Secrets Manager, Vercel Secrets, etc.)
   - Never commit `.env` files

2. **CORS:**
   - Restrict origins in production: `CORSMiddleware(allow_origins=["https://app.example.com"])`

3. **Authentication:**
   - Add JWT or OAuth2 to API endpoints (use FastAPI `security` module)

4. **Rate limiting:**
   - Use `slowapi` package or API Gateway rate limiting

5. **Audit logging:**
   - All scoring actions logged to Postgres for compliance

## Troubleshooting

**API returns 500 errors:**
- Check Redis connection: `redis-cli ping`
- Check worker logs: `docker compose logs worker`
- Verify env vars are set

**Slow scoring responses:**
- Check if local NLP models are loaded (first request slower)
- Use `/score?use_ai_agent=false` to disable AI (faster)
- Consider async mode for high throughput

**Streaming updates not arriving:**
- Ensure Redis pub/sub is working: `redis-cli SUBSCRIBE scoring_workflow`
- Check browser console for JavaScript errors
- Verify job IDs are correct

## Contributing

1. Fork the repo
2. Create a feature branch: `git checkout -b feature/my-feature`
3. Make changes and add tests
4. Run linting and tests locally
5. Push and open a PR

## License

See `LICENSE` file.

## Support

For issues, questions, or feature requests, open a GitHub issue or contact the team.
